{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word_bug.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1o7HFeQZ2SnaruHric3ena83uRp22_pjh","authorship_tag":"ABX9TyNFYyVGVRZVtNTZqwvLdcsZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"E0uOjyvR1dGw","colab_type":"text"},"source":["## Solving dependecies"]},{"cell_type":"markdown","metadata":{"id":"QWnFw3kDV0R4","colab_type":"text"},"source":["### Git repo"]},{"cell_type":"code","metadata":{"id":"_qFnZfB41J7D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"4e9c4d65-1ffb-452f-d158-0f6b6d601f7b","executionInfo":{"status":"ok","timestamp":1587921448418,"user_tz":-120,"elapsed":7128,"user":{"displayName":"Josip Jukic","photoUrl":"","userId":"16297184793715183143"}}},"source":["! git clone https://github.com/josipjukic/Adversarial-NLP.git\n","% cd /content/Adversarial-NLP/src"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'Adversarial-NLP'...\n","remote: Enumerating objects: 224, done.\u001b[K\n","remote: Counting objects:   0% (1/224)\u001b[K\rremote: Counting objects:   1% (3/224)\u001b[K\rremote: Counting objects:   2% (5/224)\u001b[K\rremote: Counting objects:   3% (7/224)\u001b[K\rremote: Counting objects:   4% (9/224)\u001b[K\rremote: Counting objects:   5% (12/224)\u001b[K\rremote: Counting objects:   6% (14/224)\u001b[K\rremote: Counting objects:   7% (16/224)\u001b[K\rremote: Counting objects:   8% (18/224)\u001b[K\rremote: Counting objects:   9% (21/224)\u001b[K\rremote: Counting objects:  10% (23/224)\u001b[K\rremote: Counting objects:  11% (25/224)\u001b[K\rremote: Counting objects:  12% (27/224)\u001b[K\rremote: Counting objects:  13% (30/224)\u001b[K\rremote: Counting objects:  14% (32/224)\u001b[K\rremote: Counting objects:  15% (34/224)\u001b[K\rremote: Counting objects:  16% (36/224)\u001b[K\rremote: Counting objects:  17% (39/224)\u001b[K\rremote: Counting objects:  18% (41/224)\u001b[K\rremote: Counting objects:  19% (43/224)\u001b[K\rremote: Counting objects:  20% (45/224)\u001b[K\rremote: Counting objects:  21% (48/224)\u001b[K\rremote: Counting objects:  22% (50/224)\u001b[K\rremote: Counting objects:  23% (52/224)\u001b[K\rremote: Counting objects:  24% (54/224)\u001b[K\rremote: Counting objects:  25% (56/224)\u001b[K\rremote: Counting objects:  26% (59/224)\u001b[K\rremote: Counting objects:  27% (61/224)\u001b[K\rremote: Counting objects:  28% (63/224)\u001b[K\rremote: Counting objects:  29% (65/224)\u001b[K\rremote: Counting objects:  30% (68/224)\u001b[K\rremote: Counting objects:  31% (70/224)\u001b[K\rremote: Counting objects:  32% (72/224)\u001b[K\rremote: Counting objects:  33% (74/224)\u001b[K\rremote: Counting objects:  34% (77/224)\u001b[K\rremote: Counting objects:  35% (79/224)\u001b[K\rremote: Counting objects:  36% (81/224)\u001b[K\rremote: Counting objects:  37% (83/224)\u001b[K\rremote: Counting objects:  38% (86/224)\u001b[K\rremote: Counting objects:  39% (88/224)\u001b[K\rremote: Counting objects:  40% (90/224)\u001b[K\rremote: Counting objects:  41% (92/224)\u001b[K\rremote: Counting objects:  42% (95/224)\u001b[K\rremote: Counting objects:  43% (97/224)\u001b[K\rremote: Counting objects:  44% (99/224)\u001b[K\rremote: Counting objects:  45% (101/224)\u001b[K\rremote: Counting objects:  46% (104/224)\u001b[K\rremote: Counting objects:  47% (106/224)\u001b[K\rremote: Counting objects:  48% (108/224)\u001b[K\rremote: Counting objects:  49% (110/224)\u001b[K\rremote: Counting objects:  50% (112/224)\u001b[K\rremote: Counting objects:  51% (115/224)\u001b[K\rremote: Counting objects:  52% (117/224)\u001b[K\rremote: Counting objects:  53% (119/224)\u001b[K\rremote: Counting objects:  54% (121/224)\u001b[K\rremote: Counting objects:  55% (124/224)\u001b[K\rremote: Counting objects:  56% (126/224)\u001b[K\rremote: Counting objects:  57% (128/224)\u001b[K\rremote: Counting objects:  58% (130/224)\u001b[K\rremote: Counting objects:  59% (133/224)\u001b[K\rremote: Counting objects:  60% (135/224)\u001b[K\rremote: Counting objects:  61% (137/224)\u001b[K\rremote: Counting objects:  62% (139/224)\u001b[K\rremote: Counting objects:  63% (142/224)\u001b[K\rremote: Counting objects:  64% (144/224)\u001b[K\rremote: Counting objects:  65% (146/224)\u001b[K\rremote: Counting objects:  66% (148/224)\u001b[K\rremote: Counting objects:  67% (151/224)\u001b[K\rremote: Counting objects:  68% (153/224)\u001b[K\rremote: Counting objects:  69% (155/224)\u001b[K\rremote: Counting objects:  70% (157/224)\u001b[K\rremote: Counting objects:  71% (160/224)\u001b[K\rremote: Counting objects:  72% (162/224)\u001b[K\rremote: Counting objects:  73% (164/224)\u001b[K\rremote: Counting objects:  74% (166/224)\u001b[K\rremote: Counting objects:  75% (168/224)\u001b[K\rremote: Counting objects:  76% (171/224)\u001b[K\rremote: Counting objects:  77% (173/224)\u001b[K\rremote: Counting objects:  78% (175/224)\u001b[K\rremote: Counting objects:  79% (177/224)\u001b[K\rremote: Counting objects:  80% (180/224)\u001b[K\rremote: Counting objects:  81% (182/224)\u001b[K\rremote: Counting objects:  82% (184/224)\u001b[K\rremote: Counting objects:  83% (186/224)\u001b[K\rremote: Counting objects:  84% (189/224)\u001b[K\rremote: Counting objects:  85% (191/224)\u001b[K\rremote: Counting objects:  86% (193/224)\u001b[K\rremote: Counting objects:  87% (195/224)\u001b[K\rremote: Counting objects:  88% (198/224)\u001b[K\rremote: Counting objects:  89% (200/224)\u001b[K\rremote: Counting objects:  90% (202/224)\u001b[K\rremote: Counting objects:  91% (204/224)\u001b[K\rremote: Counting objects:  92% (207/224)\u001b[K\rremote: Counting objects:  93% (209/224)\u001b[K\rremote: Counting objects:  94% (211/224)\u001b[K\rremote: Counting objects:  95% (213/224)\u001b[K\rremote: Counting objects:  96% (216/224)\u001b[K\rremote: Counting objects:  97% (218/224)\u001b[K\rremote: Counting objects:  98% (220/224)\u001b[K\rremote: Counting objects:  99% (222/224)\u001b[K\rremote: Counting objects: 100% (224/224)\u001b[K\rremote: Counting objects: 100% (224/224), done.\u001b[K\n","remote: Compressing objects:   0% (1/151)\u001b[K\rremote: Compressing objects:   1% (2/151)\u001b[K\rremote: Compressing objects:   2% (4/151)\u001b[K\rremote: Compressing objects:   3% (5/151)\u001b[K\rremote: Compressing objects:   4% (7/151)\u001b[K\rremote: Compressing objects:   5% (8/151)\u001b[K\rremote: Compressing objects:   6% (10/151)\u001b[K\rremote: Compressing objects:   7% (11/151)\u001b[K\rremote: Compressing objects:   8% (13/151)\u001b[K\rremote: Compressing objects:   9% (14/151)\u001b[K\rremote: Compressing objects:  10% (16/151)\u001b[K\rremote: Compressing objects:  11% (17/151)\u001b[K\rremote: Compressing objects:  12% (19/151)\u001b[K\rremote: Compressing objects:  13% (20/151)\u001b[K\rremote: Compressing objects:  14% (22/151)\u001b[K\rremote: Compressing objects:  15% (23/151)\u001b[K\rremote: Compressing objects:  16% (25/151)\u001b[K\rremote: Compressing objects:  17% (26/151)\u001b[K\rremote: Compressing objects:  18% (28/151)\u001b[K\rremote: Compressing objects:  19% (29/151)\u001b[K\rremote: Compressing objects:  20% (31/151)\u001b[K\rremote: Compressing objects:  21% (32/151)\u001b[K\rremote: Compressing objects:  22% (34/151)\u001b[K\rremote: Compressing objects:  23% (35/151)\u001b[K\rremote: Compressing objects:  24% (37/151)\u001b[K\rremote: Compressing objects:  25% (38/151)\u001b[K\rremote: Compressing objects:  26% (40/151)\u001b[K\rremote: Compressing objects:  27% (41/151)\u001b[K\rremote: Compressing objects:  28% (43/151)\u001b[K\rremote: Compressing objects:  29% (44/151)\u001b[K\rremote: Compressing objects:  30% (46/151)\u001b[K\rremote: Compressing objects:  31% (47/151)\u001b[K\rremote: Compressing objects:  32% (49/151)\u001b[K\rremote: Compressing objects:  33% (50/151)\u001b[K\rremote: Compressing objects:  34% (52/151)\u001b[K\rremote: Compressing objects:  35% (53/151)\u001b[K\rremote: Compressing objects:  36% (55/151)\u001b[K\rremote: Compressing objects:  37% (56/151)\u001b[K\rremote: Compressing objects:  38% (58/151)\u001b[K\rremote: Compressing objects:  39% (59/151)\u001b[K\rremote: Compressing objects:  40% (61/151)\u001b[K\rremote: Compressing objects:  41% (62/151)\u001b[K\rremote: Compressing objects:  42% (64/151)\u001b[K\rremote: Compressing objects:  43% (65/151)\u001b[K\rremote: Compressing objects:  44% (67/151)\u001b[K\rremote: Compressing objects:  45% (68/151)\u001b[K\rremote: Compressing objects:  46% (70/151)\u001b[K\rremote: Compressing objects:  47% (71/151)\u001b[K\rremote: Compressing objects:  48% (73/151)\u001b[K\rremote: Compressing objects:  49% (74/151)\u001b[K\rremote: Compressing objects:  50% (76/151)\u001b[K\rremote: Compressing objects:  51% (78/151)\u001b[K\rremote: Compressing objects:  52% (79/151)\u001b[K\rremote: Compressing objects:  53% (81/151)\u001b[K\rremote: Compressing objects:  54% (82/151)\u001b[K\rremote: Compressing objects:  55% (84/151)\u001b[K\rremote: Compressing objects:  56% (85/151)\u001b[K\rremote: Compressing objects:  57% (87/151)\u001b[K\rremote: Compressing objects:  58% (88/151)\u001b[K\rremote: Compressing objects:  59% (90/151)\u001b[K\rremote: Compressing objects:  60% (91/151)\u001b[K\rremote: Compressing objects:  61% (93/151)\u001b[K\rremote: Compressing objects:  62% (94/151)\u001b[K\rremote: Compressing objects:  63% (96/151)\u001b[K\rremote: Compressing objects:  64% (97/151)\u001b[K\rremote: Compressing objects:  65% (99/151)\u001b[K\rremote: Compressing objects:  66% (100/151)\u001b[K\rremote: Compressing objects:  67% (102/151)\u001b[K\rremote: Compressing objects:  68% (103/151)\u001b[K\rremote: Compressing objects:  69% (105/151)\u001b[K\rremote: Compressing objects:  70% (106/151)\u001b[K\rremote: Compressing objects:  71% (108/151)\u001b[K\rremote: Compressing objects:  72% (109/151)\u001b[K\rremote: Compressing objects:  73% (111/151)\u001b[K\rremote: Compressing objects:  74% (112/151)\u001b[K\rremote: Compressing objects:  75% (114/151)\u001b[K\rremote: Compressing objects:  76% (115/151)\u001b[K\rremote: Compressing objects:  77% (117/151)\u001b[K\rremote: Compressing objects:  78% (118/151)\u001b[K\rremote: Compressing objects:  79% (120/151)\u001b[K\rremote: Compressing objects:  80% (121/151)\u001b[K\rremote: Compressing objects:  81% (123/151)\u001b[K\rremote: Compressing objects:  82% (124/151)\u001b[K\rremote: Compressing objects:  83% (126/151)\u001b[K\rremote: Compressing objects:  84% (127/151)\u001b[K\rremote: Compressing objects:  85% (129/151)\u001b[K\rremote: Compressing objects:  86% (130/151)\u001b[K\rremote: Compressing objects:  87% (132/151)\u001b[K\rremote: Compressing objects:  88% (133/151)\u001b[K\rremote: Compressing objects:  89% (135/151)\u001b[K\rremote: Compressing objects:  90% (136/151)\u001b[K\rremote: Compressing objects:  91% (138/151)\u001b[K\rremote: Compressing objects:  92% (139/151)\u001b[K\rremote: Compressing objects:  93% (141/151)\u001b[K\rremote: Compressing objects:  94% (142/151)\u001b[K\rremote: Compressing objects:  95% (144/151)\u001b[K\rremote: Compressing objects:  96% (145/151)\u001b[K\rremote: Compressing objects:  97% (147/151)\u001b[K\rremote: Compressing objects:  98% (148/151)\u001b[K\rremote: Compressing objects:  99% (150/151)\u001b[K\rremote: Compressing objects: 100% (151/151)\u001b[K\rremote: Compressing objects: 100% (151/151), done.\u001b[K\n","Receiving objects:   0% (1/224)   \rReceiving objects:   1% (3/224)   \rReceiving objects:   2% (5/224)   \rReceiving objects:   3% (7/224)   \rReceiving objects:   4% (9/224)   \rReceiving objects:   5% (12/224)   \rReceiving objects:   6% (14/224)   \rReceiving objects:   7% (16/224)   \rReceiving objects:   8% (18/224)   \rReceiving objects:   9% (21/224)   \rReceiving objects:  10% (23/224)   \rReceiving objects:  11% (25/224)   \rReceiving objects:  12% (27/224)   \rReceiving objects:  13% (30/224)   \rReceiving objects:  14% (32/224)   \rReceiving objects:  15% (34/224)   \rReceiving objects:  16% (36/224)   \rReceiving objects:  17% (39/224)   \rReceiving objects:  18% (41/224)   \rReceiving objects:  19% (43/224)   \rReceiving objects:  20% (45/224)   \rReceiving objects:  21% (48/224)   \rReceiving objects:  22% (50/224)   \rReceiving objects:  23% (52/224)   \rReceiving objects:  24% (54/224)   \rReceiving objects:  25% (56/224)   \rReceiving objects:  26% (59/224)   \rReceiving objects:  27% (61/224)   \rReceiving objects:  28% (63/224)   \rReceiving objects:  29% (65/224)   \rReceiving objects:  30% (68/224)   \rReceiving objects:  31% (70/224)   \rReceiving objects:  32% (72/224)   \rReceiving objects:  33% (74/224)   \rReceiving objects:  34% (77/224)   \rReceiving objects:  35% (79/224)   \rReceiving objects:  36% (81/224)   \rReceiving objects:  37% (83/224)   \rReceiving objects:  38% (86/224)   \rReceiving objects:  39% (88/224)   \rReceiving objects:  40% (90/224)   \rReceiving objects:  41% (92/224)   \rReceiving objects:  42% (95/224)   \rReceiving objects:  43% (97/224)   \rReceiving objects:  44% (99/224)   \rReceiving objects:  45% (101/224)   \rReceiving objects:  46% (104/224)   \rReceiving objects:  47% (106/224)   \rReceiving objects:  48% (108/224)   \rReceiving objects:  49% (110/224)   \rReceiving objects:  50% (112/224)   \rReceiving objects:  51% (115/224)   \rReceiving objects:  52% (117/224)   \rReceiving objects:  53% (119/224)   \rReceiving objects:  54% (121/224)   \rReceiving objects:  55% (124/224)   \rReceiving objects:  56% (126/224)   \rReceiving objects:  57% (128/224)   \rReceiving objects:  58% (130/224)   \rReceiving objects:  59% (133/224)   \rReceiving objects:  60% (135/224)   \rReceiving objects:  61% (137/224)   \rReceiving objects:  62% (139/224)   \rReceiving objects:  63% (142/224)   \rReceiving objects:  64% (144/224)   \rReceiving objects:  65% (146/224)   \rReceiving objects:  66% (148/224)   \rReceiving objects:  67% (151/224)   \rReceiving objects:  68% (153/224)   \rremote: Total 224 (delta 132), reused 133 (delta 62), pack-reused 0\u001b[K\n","Receiving objects:  69% (155/224)   \rReceiving objects:  70% (157/224)   \rReceiving objects:  71% (160/224)   \rReceiving objects:  72% (162/224)   \rReceiving objects:  73% (164/224)   \rReceiving objects:  74% (166/224)   \rReceiving objects:  75% (168/224)   \rReceiving objects:  76% (171/224)   \rReceiving objects:  77% (173/224)   \rReceiving objects:  78% (175/224)   \rReceiving objects:  79% (177/224)   \rReceiving objects:  80% (180/224)   \rReceiving objects:  81% (182/224)   \rReceiving objects:  82% (184/224)   \rReceiving objects:  83% (186/224)   \rReceiving objects:  84% (189/224)   \rReceiving objects:  85% (191/224)   \rReceiving objects:  86% (193/224)   \rReceiving objects:  87% (195/224)   \rReceiving objects:  88% (198/224)   \rReceiving objects:  89% (200/224)   \rReceiving objects:  90% (202/224)   \rReceiving objects:  91% (204/224)   \rReceiving objects:  92% (207/224)   \rReceiving objects:  93% (209/224)   \rReceiving objects:  94% (211/224)   \rReceiving objects:  95% (213/224)   \rReceiving objects:  96% (216/224)   \rReceiving objects:  97% (218/224)   \rReceiving objects:  98% (220/224)   \rReceiving objects:  99% (222/224)   \rReceiving objects: 100% (224/224)   \rReceiving objects: 100% (224/224), 75.47 KiB | 7.55 MiB/s, done.\n","Resolving deltas:   0% (0/132)   \rResolving deltas:   3% (5/132)   \rResolving deltas:   9% (12/132)   \rResolving deltas:  21% (29/132)   \rResolving deltas:  25% (33/132)   \rResolving deltas:  30% (40/132)   \rResolving deltas:  34% (45/132)   \rResolving deltas:  36% (48/132)   \rResolving deltas:  39% (52/132)   \rResolving deltas:  43% (57/132)   \rResolving deltas:  46% (62/132)   \rResolving deltas:  49% (65/132)   \rResolving deltas:  50% (67/132)   \rResolving deltas:  55% (73/132)   \rResolving deltas:  57% (76/132)   \rResolving deltas:  63% (84/132)   \rResolving deltas:  65% (86/132)   \rResolving deltas:  75% (100/132)   \rResolving deltas:  76% (101/132)   \rResolving deltas:  77% (102/132)   \rResolving deltas:  84% (111/132)   \rResolving deltas:  85% (113/132)   \rResolving deltas:  87% (115/132)   \rResolving deltas:  88% (117/132)   \rResolving deltas:  91% (121/132)   \rResolving deltas:  93% (123/132)   \rResolving deltas:  95% (126/132)   \rResolving deltas: 100% (132/132)   \rResolving deltas: 100% (132/132), done.\n","/content/Adversarial-NLP/src\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NWNmPxPDWCJ2","colab_type":"text"},"source":["### Embeddings"]},{"cell_type":"code","metadata":{"id":"YxLhCQAtWA3n","colab_type":"code","colab":{}},"source":["% mkdir .vector_cache\n","% cp '/content/drive/My Drive/Master Thesis/glove/glove.6B.100d.txt.pt' .vector_cache/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iuWKabZYWF_q","colab_type":"text"},"source":["### NLTK data"]},{"cell_type":"code","metadata":{"id":"txnHPPV8wopS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"cdc4d41d-036e-4450-de65-422107a59628","executionInfo":{"status":"ok","timestamp":1587921458960,"user_tz":-120,"elapsed":15613,"user":{"displayName":"Josip Jukic","photoUrl":"","userId":"16297184793715183143"}}},"source":["import nltk\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"OKEZU9wG1wuS","colab_type":"text"},"source":["## Dataset save/load"]},{"cell_type":"code","metadata":{"id":"fAG4WVtC1LUe","colab_type":"code","colab":{}},"source":["import torch\n","from torchtext import data\n","from torchtext import datasets\n","import spacy\n","import random\n","from preprocessing import imdb_preprocess\n","from data_utils import load_dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"joKNAe6fWWbh","colab_type":"code","colab":{}},"source":["SEED = 42\n","torch.manual_seed(SEED)\n","LOAD_PATH = '/content/drive/My Drive/Master Thesis/IMDB'\n","MAX_VOCAB_SIZE = 25_000\n","EMBEDDINGS_FILE = 'glove.6B.100d'\n","\n","splits, fields = load_dataset(LOAD_PATH,\n","                              include_lengths=True,\n","                              lower=False,\n","                              stop_words=None)\n","train_data, valid_data, test_data = splits\n","TEXT, LABEL, RAW, ID = fields\n","RAW.is_target = ID.is_target = False\n","LABEL.build_vocab(train_data)\n","TEXT.build_vocab(train_data, \n","                 max_size = MAX_VOCAB_SIZE, \n","                 vectors = EMBEDDINGS_FILE, \n","                 unk_init = torch.Tensor.normal_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WSSsflavpNZD","colab_type":"code","colab":{}},"source":["from argparse import Namespace\n","from data_utils import expand_paths\n","from models import PackedLSTM\n","\n","args = Namespace(\n","    # Data and Path hyper parameters\n","    model_path='/content/drive/My Drive/Master Thesis/torch_models/imdb/imdb_model.torch',\n","    train_state_file='train_state.json',\n","    save_dir='/content/drive/My Drive/Master Thesis/torch_models/imdb/',\n","    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token],\n","    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token],\n","    # Model hyper parameters\n","    input_dim = len(TEXT.vocab),\n","    embedding_dim=100,\n","    hidden_dim=256,\n","    output_dim = 1,\n","    num_layers=2,\n","    bidirectional=True,\n","    # Training hyper parameter\n","    seed=SEED,\n","    learning_rate=0.001,\n","    dropout_p=0.5,\n","    batch_size=64,\n","    num_epochs=20,\n","    early_stopping_criteria=5,\n","    # Runtime option\n","    reload_from_files=True,\n","    expand_filepaths_to_save_dir=True,\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",")\n","\n","pretrained_embeddings = TEXT.vocab.vectors\n","pretrained_embeddings[args.UNK_IDX] = torch.zeros(args.embedding_dim)\n","pretrained_embeddings[args.PAD_IDX] = torch.zeros(args.embedding_dim)\n","\n","model = PackedLSTM(\n","    args.embedding_dim, \n","    args.hidden_dim, \n","    args.output_dim, \n","    args.num_layers,\n","    pretrained_embeddings,\n","    args.bidirectional,\n","    args.dropout_p, \n","    args.PAD_IDX,\n","    args.device\n",")\n","model.load_state_dict(torch.load(args.model_path, map_location=args.device))\n","model = model.to(args.device)\n","model.eval()\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=512,\n","    sort_within_batch=True,\n","    sort_key = lambda x: len(x.text),\n","    device=args.device)\n","iterator = dict(train=train_iterator, valid=valid_iterator, test=test_iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVfNJGOvCbxL","colab_type":"code","colab":{}},"source":["def word_target(model, batch, y_preds, num_classes, device):\n","    inputs = batch[0]\n","    losses = torch.zeros(inputs.shape)\n","    target = None\n","    for i in range(inputs.shape[0]):\n","        if target:\n","            index, vals = target\n","            inputs[i-1,:] = vals\n","        target = (i, torch.clone(inputs[i,:]))\n","        inputs[i,:] = 0\n","        with torch.no_grad():\n","            out = model.predict_proba(batch)\n","            if num_classes == 2:\n","                out = torch.cat([1.-out, out], dim=1)\n","            losses[i,:] = out.gather(1, y_preds).squeeze()\n","    \n","    if target:\n","        index, vals = target\n","        inputs[-1,:] = vals\n","    return 1.-losses\n","\n","\n","def temporal(model, batch, y_preds, num_classes, device):\n","    inputs, lengths = batch\n","    new_preds = torch.zeros(inputs.shape)\n","    losses = torch.zeros(inputs.shape)\n","    for i in range(inputs.shape[0]):\n","        preinputs = inputs[:i+1,:]\n","        with torch.no_grad():\n","            new_lengths = torch.min(lengths, torch.tensor(i+1).to(device))\n","            preout = model.predict_proba((preinputs, new_lengths))\n","            if num_classes == 2:\n","                preout = torch.cat([1.-preout, preout], dim=1).to(device)\n","            new_preds[i,:] = preout.gather(1, y_preds).squeeze()\n","            \n","    losses[0,:] = new_preds[0,:] - 1.0/num_classes\n","    for i in range(1, inputs.shape[0]):\n","        losses[i,:] = new_preds[i,:] - new_preds[i-1,:]\n","\n","    return losses\n","\n","\n","def temporal_tail(model, batch, y_preds, num_classes, device):\n","    inputs, lengths = batch\n","    new_preds = torch.zeros(inputs.shape)\n","    losses = torch.zeros(inputs.shape)\n","    for i in range(inputs.shape[0]):\n","        postinputs = inputs[i:,:]\n","        with torch.no_grad():\n","            new_lengths = torch.max(lengths-i, torch.tensor(1).to(device))\n","            postout = model.predict_proba((postinputs, new_lengths))\n","            if num_classes == 2:\n","                postout = torch.cat([1.-postout, postout], dim=1).to(device)\n","            new_preds[i,:] = postout.gather(1, y_preds).squeeze()\n","            \n","    losses[-1,:] = new_preds[-1,:] - 1.0/num_classes\n","    for i in range(inputs.shape[0]-1):\n","        losses[i,:] = new_preds[i,:] - new_preds[i+1,:]\n","\n","    return losses\n","\n","\n","def combined_temporal(model, batch, y_preds, num_classes, device, alpha=1.):\n","    temporal_score = temporal(model, batch, y_preds, num_classes, device)\n","    temporal_tail_score = temporal_tail(model, batch, y_preds, num_classes, device)\n","    return temporal_score + alpha*temporal_tail_score\n","\n","\n","def random(inputs, *args, **kwargs):\n","    losses = torch.rand(inputs.size()[0], inputs.size()[1])\n","    return losses"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLKthJhJmjxG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"dab56928-3470-4c90-938e-ee649c362f9f","executionInfo":{"status":"ok","timestamp":1587923282909,"user_tz":-120,"elapsed":3097,"user":{"displayName":"Josip Jukic","photoUrl":"","userId":"16297184793715183143"}}},"source":["from data_utils import spacy_revtok\n","import numpy as np\n","\n","num_classes = len(LABEL.vocab)\n","nlp = spacy.load('en', disable=['parser', 'tagger', 'ner', 'textcat'])\n","\n","def reconstruct(tensor, vocab):\n","    words = [vocab.itos[idx] for idx in tensor]\n","    return ' '.join(words)\n","\n","def adversarial_text(raw, nlp, indices, transform):\n","    adv_words = [token.text_with_ws for token in nlp(raw)]\n","    for i in indices:\n","        if i >= len(adv_words): continue\n","        adv_words[i] = transform(adv_words[i])\n","    return ''.join(adv_words)\n","\n","def binary_accuracy(model, batch):\n","    y_pred = model.predict(batch.text).to(args.device).squeeze()\n","    correct = (y_pred == batch.label).float()\n","    return (correct.sum() / len(correct)).item()\n","\n","homos = {'-':'˗','9':'৭','8':'Ȣ','7':'𝟕','6':'б','5':'Ƽ','4':'Ꮞ','3':'Ʒ','2':'ᒿ','1':'l','0':'O',\n","         \"'\":'`','a': 'ɑ', 'b': 'Ь', 'c': 'ϲ', 'd': 'ԁ', 'e': 'е', 'f': '𝚏', 'g': 'ɡ', 'h': 'հ',\n","         'i': 'і', 'j': 'ϳ', 'k': '𝒌', 'l': 'ⅼ', 'm': 'ｍ', 'n': 'ո', 'o':'о', 'p': 'р', 'q': 'ԛ',\n","         'r': 'ⲅ', 's': 'ѕ', 't': '𝚝', 'u': 'ս', 'v': 'ѵ', 'w': 'ԝ', 'x': '×', 'y': 'у', 'z': 'ᴢ'}\n","\n","def homoglyph(word):\n","    N = len(word)-1 if word[-1] == ' ' else len(word)\n","    N = max(1, N)\n","    s = np.random.randint(0, N)\n","    if word[s] in homos: \n","        adv_char = homos[word[s]]\n","    else:\n","        adv_char = word[s]\n","    adv_word = word[:s] + adv_char + word[s+1:]\n","    return adv_word\n","\n","def remove_char(word):\n","    N = len(word)-1 if word[-1] == ' ' else len(word)\n","    N = max(1, N)\n","    s = np.random.randint(0, N)\n","    adv_word = word[:s] + word[s+1:]\n","    return adv_word\n","\n","def flip_char(word):\n","    N = len(word)-1 if word[-1] == ' ' else len(word)\n","    N = max(1, N)\n","    s = np.random.randint(0, N)\n","    letter = ord(word[s])\n","    adv_char = np.random.randint(0,25) + 97\n","    adv_word = word[:s] + chr(adv_char) + word[s+1:]\n","    return adv_word\n","\n","attack_power = 20\n","reg_acc = 0.\n","adv_acc = 0.\n","for batch_index, batch in enumerate(iterator['test'], 1):\n","    # print('Length: ', batch.text[0].shape[0])\n","    print('Batch: ', batch_index)\n","    x_in, lengths = batch.text\n","    y_preds = model.predict(batch.text).to(args.device)\n","    losses = word_target(model=model, batch=batch.text,\n","                         y_preds=y_preds, num_classes=num_classes,\n","                         device=args.device)\n","    sorted_losses, indices = torch.sort(losses, dim=0, descending=True)\n","    acc_t = binary_accuracy(model, batch)\n","    reg_acc += (acc_t - reg_acc) / batch_index\n","\n","\n","    for i in range(x_in.shape[1]):\n","        inds = indices[0:attack_power,i]\n","        x_in[inds,i] = 0\n","        # print(adversarial_text(batch.raw[i], nlp, inds, flip_char))\n","        # print(batch.raw[i])\n","\n","    acc_t = binary_accuracy(model, batch)\n","    adv_acc += (acc_t - adv_acc) / batch_index\n","    print(reg_acc, adv_acc)\n","    print('-----------------------------')\n","\n","    \n","    break"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Batch:  1\n","Tpis movip wxs d suprise gor mw while m kas eurfing from channel to channel... I don't know why but it filled in me with warmth and hapsiness. Tris is what d digh budget movie ckn not uo mostly. I likef iua this is \"a must sye\" one...\n","This movie was a suprise for me while I was surfing from channel to channel... I don't know why but it filled in me with warmth and happiness. This is what a high budget movie can not do mostly. I liked it, this is \"a must see\" one...\n","0.89453125 0.263671875\n","-----------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ih9PCI-C7NNO","colab_type":"code","colab":{}},"source":["from data_utils import save_dataset\n","\n","SAVE_PATH = '/content/drive/My Drive/Master Thesis/IMDB'\n","\n","dataset = dict(train=train_data, test=test_data, valid=valid_data)\n","save_dataset(dataset, SAVE_PATH)"],"execution_count":0,"outputs":[]}]}