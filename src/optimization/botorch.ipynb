{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "X = torch.rand(20, 2) - 0.5\n",
    "Y = (torch.sin(2 * math.pi * X[:, 0]) + torch.cos(2 * math.pi * X[:, 1])).unsqueeze(-1)\n",
    "Y += 0.1 * torch.randn_like(Y)\n",
    "\n",
    "gp = SingleTaskGP(X, Y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_model(mll);\n",
    "\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "\n",
    "UCB = UpperConfidenceBound(gp, beta=0.1)\n",
    "\n",
    "import cma\n",
    "import numpy as np\n",
    "\n",
    "# get initial condition for CMAES in numpy form\n",
    "# note that CMAES expects a different shape (no explicit q-batch dimension)\n",
    "x0 = np.random.rand(2)\n",
    "\n",
    "# create the CMA-ES optimizer\n",
    "es = cma.CMAEvolutionStrategy(\n",
    "    x0=x0,\n",
    "    sigma0=0.2,\n",
    "    inopts={'bounds': [0, 1], \"popsize\": 50},\n",
    ")\n",
    "\n",
    "# speed up things by telling pytorch not to generate a compute graph in the background\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Run the optimization loop using the ask/tell interface -- this uses \n",
    "    # PyCMA's default settings, see the PyCMA documentation for how to modify these\n",
    "    while not es.stop():\n",
    "        xs = es.ask()  # as for new points to evaluate\n",
    "        # convert to Tensor for evaluating the acquisition function\n",
    "        X = torch.tensor(xs, device=X.device, dtype=X.dtype)\n",
    "        # evaluate the acquisition function (optimizer assumes we're minimizing)\n",
    "        Y = - UCB(X.unsqueeze(-2))  # acquisition functions require an explicit q-batch dimension\n",
    "        y = Y.view(-1).double().numpy()  # convert result to numpy array\n",
    "        es.tell(xs, y)  # return the result to the optimizer\n",
    "\n",
    "# convert result back to a torch tensor\n",
    "best_x = torch.from_numpy(es.best.x).to(X)\n",
    "\n",
    "best_x"
   ]
  }
 ]
}