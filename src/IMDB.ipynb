{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IMDB.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"18uDYEcOz4RGYEy4L_FK-76399Wyh_Fbw","authorship_tag":"ABX9TyMrrhvpcG+lAp06SPY+qQzl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f55f51bdaa474b058aae68339f8adf82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_446969938e1749abbde76e305d93fb20","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_451078f30efc4e6194b965e71f1e98a8","IPY_MODEL_63ed84050aea49f8b804139735593429"]}},"446969938e1749abbde76e305d93fb20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"451078f30efc4e6194b965e71f1e98a8":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7853268244be48219f706bc3e909ec61","_dom_classes":[],"description":"training routine: 100%","_model_name":"IntProgressModel","bar_style":"","max":5,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0c700709e8744ea93feb67e6a3beb2a"}},"63ed84050aea49f8b804139735593429":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d4868598903453eb5f695c6b22f426f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5/5 [02:40&lt;00:00, 32.28s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a74f0dc8ca942eab216a0ddc29f7827"}},"7853268244be48219f706bc3e909ec61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c0c700709e8744ea93feb67e6a3beb2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d4868598903453eb5f695c6b22f426f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7a74f0dc8ca942eab216a0ddc29f7827":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6bb0cb0ba6344521a78e0bed92f8fadd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c8db8ce766c04709a797e7465ae9a8fa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_32966e234a4548029e5d6313919282c1","IPY_MODEL_d001aca3a2034288a8c02caa4330da9f"]}},"c8db8ce766c04709a797e7465ae9a8fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32966e234a4548029e5d6313919282c1":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2d8a9d4d0a4847bf8716a3759fcb7ca2","_dom_classes":[],"description":"Train set: 100%","_model_name":"IntProgressModel","bar_style":"","max":274,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":273,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e7f33f0faee4139b0a1bac6d0b185ef"}},"d001aca3a2034288a8c02caa4330da9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0cce80787ce149fdb48d8d0761aa6d60","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 273/274 [02:36&lt;00:09,  9.61s/it, acc=0.683, loss=0.588]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de4112f79c4d48bea559326348e57c08"}},"2d8a9d4d0a4847bf8716a3759fcb7ca2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9e7f33f0faee4139b0a1bac6d0b185ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0cce80787ce149fdb48d8d0761aa6d60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"de4112f79c4d48bea559326348e57c08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1aff443e0d34252a3b03b1a20aaea58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_32223dab9f664e63a857ff2f71e24b89","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1e26d93872094dbcba4efb2ea3853efe","IPY_MODEL_4006ec3536e04bedaeba01f281900043"]}},"32223dab9f664e63a857ff2f71e24b89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e26d93872094dbcba4efb2ea3853efe":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_739fc68a28204ef2b066e78c4816ff3d","_dom_classes":[],"description":"Valid set:  99%","_model_name":"IntProgressModel","bar_style":"","max":118,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":117,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c7b9fb6cd031422bb9afe90c5f9e5e54"}},"4006ec3536e04bedaeba01f281900043":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f87053b2e4a3439b825698c25c6813d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 117/118 [02:40&lt;00:00,  7.77it/s, acc=0.774, loss=0.483]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_380f1338c3264e61b7fb45945d7e1bed"}},"739fc68a28204ef2b066e78c4816ff3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c7b9fb6cd031422bb9afe90c5f9e5e54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f87053b2e4a3439b825698c25c6813d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"380f1338c3264e61b7fb45945d7e1bed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"E0uOjyvR1dGw","colab_type":"text"},"source":["## Cloning git repository for dependencies\n"]},{"cell_type":"code","metadata":{"id":"_qFnZfB41J7D","colab_type":"code","outputId":"0f31ef0d-2ed4-4ac3-e786-e6490c011e97","executionInfo":{"status":"ok","timestamp":1586888122866,"user_tz":-120,"elapsed":2642,"user":{"displayName":"Josip Jukic","photoUrl":"","userId":"16297184793715183143"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["! git clone https://github.com/josipjukic/Adversarial-NLP.git\n","% cd /content/Adversarial-NLP/src"],"execution_count":123,"outputs":[{"output_type":"stream","text":["fatal: destination path 'Adversarial-NLP' already exists and is not an empty directory.\n","/content/Adversarial-NLP/src\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OKEZU9wG1wuS","colab_type":"text"},"source":["## IMDb experiments"]},{"cell_type":"code","metadata":{"id":"fAG4WVtC1LUe","colab_type":"code","colab":{}},"source":["import torch\n","from torchtext import data\n","from torchtext import datasets\n","import spacy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VA5ROBbW173-","colab_type":"code","colab":{}},"source":["SEED = 42\n","torch.manual_seed(SEED)\n","\n","text_field = data.Field(tokenize='spacy', include_lengths=True)\n","label_field = data.LabelField(dtype=torch.float)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KFrk0FiT2SDX","colab_type":"code","colab":{}},"source":["train_data, test_data = datasets.IMDB.splits(text_field, label_field)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A3hTmrrnHNDV","colab_type":"code","colab":{}},"source":["import random\n","\n","train_data, valid_data = train_data.split(random_state = random.seed(SEED))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWAAilBZ1UIh","colab_type":"code","colab":{}},"source":["MAX_VOCAB_SIZE = 25_000\n","EMBEDDINGS_FILE = 'glove.6B.100d'\n","\n","text_field.build_vocab(train_data, \n","                       max_size = MAX_VOCAB_SIZE, \n","                       vectors = EMBEDDINGS_FILE, \n","                       unk_init = torch.Tensor.normal_)\n","\n","label_field.build_vocab(train_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMDRwRWl1UIl","colab_type":"code","colab":{}},"source":["from argparse import Namespace\n","\n","args = Namespace(\n","    # Data and Path hyper parameters\n","    model_save_file='imdb_model.torch',\n","    train_state_file='train_state.json',\n","    save_dir='/content/drive/My Drive/torch_models/imdb/',\n","    PAD_IDX = text_field.vocab.stoi[text_field.pad_token],\n","    UNK_IDX = text_field.vocab.stoi[text_field.unk_token],\n","    # Model hyper parameters\n","    input_dim = len(text_field.vocab),\n","    embedding_dim=100,\n","    hidden_dim=256,\n","    output_dim = 1,\n","    num_layers=2,\n","    bidirectional=True,\n","    # Training hyper parameter\n","    seed=SEED,\n","    learning_rate=0.001,\n","    dropout_p=0.5,\n","    batch_size=64,\n","    num_epochs=5,\n","    early_stopping_criteria=5,\n","    # Runtime option\n","    reload_from_files=True,\n","    expand_filepaths_to_save_dir=True,\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",")\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size=args.batch_size,\n","    sort_within_batch=True,\n","    device=args.device)\n","\n","iterator = dict(train=train_iterator, valid=valid_iterator, test=test_iterator)\n","\n","pretrained_embeddings = text_field.vocab.vectors\n","pretrained_embeddings[args.UNK_IDX] = torch.zeros(args.embedding_dim)\n","pretrained_embeddings[args.PAD_IDX] = torch.zeros(args.embedding_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mdMWVNqu1UIq","colab_type":"code","colab":{}},"source":["from models import LSTM\n","\n","model = LSTM(\n","    args.embedding_dim, \n","    args.hidden_dim, \n","    args.output_dim, \n","    args.num_layers,\n","    pretrained_embeddings,\n","    args.bidirectional,\n","    args.dropout_p, \n","    args.PAD_IDX\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHW06qyRIC3H","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n","# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n","#                                                  mode='min', factor=0.5,\n","#                                                  patience=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"66U_i-1kkmJ1","colab_type":"code","colab":{}},"source":["import torch\n","import time\n","from data_utils import json_dump\n","\n","\n","def make_train_state(args):\n","    return {'stop_early': False,\n","            'early_stopping_step': 0,\n","            'early_stopping_best_val': float('inf'),\n","            'learning_rate': args.learning_rate,\n","            'json_path': args.train_state_file,\n","            'epoch_index': 0,\n","            'train_loss': [],\n","            'train_acc': [],\n","            'valid_loss': [],\n","            'valid_acc': [],\n","            'test_loss': [],\n","            'test_acc': [],\n","            'model_path': args.model_save_file}\n","\n","\n","def update_train_state(args, model, train_state):\n","    \"\"\"Handle the training state updates.\n","\n","    Components:\n","     - Early Stopping: Prevent overfitting.\n","     - Model Checkpoint: Model is saved if the model is better\n","\n","    :param args: main arguments\n","    :param model: model to train\n","    :param train_state: a dictionary representing the training state values\n","    :returns:\n","        a new train_state\n","    \"\"\"\n","\n","    # Save one model at least\n","    if train_state['epoch_index'] == 0:\n","        torch.save(model.state_dict(), train_state['model_path'])\n","        train_state['stop_early'] = False\n","\n","    # Save model if performance improved\n","    elif train_state['epoch_index'] >= 1:\n","        loss_tm1, loss_t = train_state['val_loss'][-2:]\n","\n","        # If loss worsened\n","        if loss_t >= train_state['early_stopping_best_val']:\n","            # Update step\n","            train_state['early_stopping_step'] += 1\n","        # Loss decreased\n","        else:\n","            # Save the best model\n","            if loss_t < train_state['early_stopping_best_val']:\n","                torch.save(model.state_dict(), train_state['model_path'])\n","\n","            # Reset early stopping step\n","            train_state['early_stopping_step'] = 0\n","\n","        # Stop early ?\n","        train_state['stop_early'] = \\\n","            train_state['early_stopping_step'] >= args.early_stopping_criteria\n","\n","    return train_state\n","\n","\n","def dump_train_state_to_json(train_state, path):\n","    obj = dict(epochs=train_state['epoch_index'],\n","               train_loss=train_state['train_loss'],\n","               train_acc=train_state['train_acc'],\n","               val_loss=train_state['valid_loss'],\n","               val_acc=train_state['valid_acc'],\n","               test_loss=train_state['test_loss'],\n","               test_acc=train_state['test_acc'])\n","    json_dump(obj, path)\n","\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs\n","\n","\n","def binary_accuracy(y_pred, y_gold):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(y_pred))\n","    correct = (rounded_preds == y_gold).float() # convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc.item()\n","\n","\n","def train(model, iterator, optimizer, criterion, train_state, notebook=True):\n","    \n","    # print('Entering training mode...')\n","\n","    running_loss = 0.\n","    running_acc = 0.\n","    num_batches = len(iterator)\n","    \n","    model.train()\n","    \n","    for batch_index, batch in enumerate(iterator, 1):\n","        # 5 step training routine\n","\n","        # --------------------------------------\n","        # 1) zero the gradients\n","        optimizer.zero_grad()\n","        \n","        # 2) compute the output\n","        x_in, lengths = batch.text\n","        y_pred = model(x_in, lengths).squeeze()\n","\n","        # 3) compute the loss\n","        loss = criterion(y_pred, batch.label)\n","        loss_t = loss.item()\n","        running_loss += (loss_t - running_loss) / batch_index\n","        \n","        # 4) use loss to produce gradients\n","        loss.backward()\n","\n","        # 5) use optimizer to take gradient step\n","        optimizer.step()\n","        # -----------------------------------------\n","\n","        # compute the accuracy\n","        acc_t = binary_accuracy(y_pred, batch.label)\n","        running_acc += (acc_t - running_acc) / batch_index\n","\n","        if notebook:\n","            # update bar\n","            train_bar.set_postfix(loss=running_loss, acc=running_acc)\n","            train_bar.update()\n","                \n","    train_state['train_loss'].append(running_loss)\n","    train_state['train_acc'].append(running_acc)\n","\n","    return running_loss, running_acc\n","\n","\n","def evaluate(model, iterator, criterion, train_state, mode='valid', notebook=True):\n","    \n","    # print(f'Entering {mode} mode...')\n","\n","    running_loss = 0.\n","    running_acc = 0.\n","    num_batches = len(iterator)\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch_index, batch in enumerate(iterator, 1):\n","            x_in, lengths = batch.text\n","            y_pred = model(x_in, lengths).squeeze()\n","\n","            loss = criterion(y_pred, batch.label)\n","            loss_t = loss.item()\n","            running_loss += (loss_t - running_loss) / batch_index\n","            \n","            acc_t = binary_accuracy(y_pred, batch.label)\n","            running_acc += (acc_t - running_acc) / batch_index\n","\n","            if notebook:\n","                # update bar\n","                val_bar.set_postfix(loss=running_loss, acc=running_acc)\n","                val_bar.update()\n","    \n","    train_state[f'{mode}_loss'].append(running_loss)\n","    train_state[f'{mode}_acc'].append(running_acc)\n","        \n","    return running_loss, running_acc\n","\n","\n","def run_experiment(args, model, iterator, optimizer, criterion, notebook=True):\n","\n","    train_state = make_train_state(args)\n","\n","    for epoch in range(args.num_epochs):\n","\n","        start_time = time.time()\n","        \n","        train_loss, train_acc = train(model, iterator['train'], optimizer,\n","                                      criterion, train_state, notebook=notebook)\n","        valid_loss, valid_acc = evaluate(model, iterator['valid'], criterion,\n","                                         train_state, notebook=notebook)\n","        \n","        end_time = time.time()\n","\n","        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","        train_state = update_train_state(args=args, model=model,\n","                                         train_state=train_state)\n","        \n","        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","        print(f'    Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","        print(f'    Valid Loss: {valid_loss:.3f} |  Valid Acc: {valid_acc*100:.2f}%')\n","\n","        if train_state['stop_early']:\n","            break\n","\n","        if notebook:\n","            # update bars\n","            train_bar.n = 0\n","            val_bar.n = 0\n","            epoch_bar.update()\n","\n","    test_loss, test_acc = evaluate(model, iterator['test'], criterion, train_state, mode='test', notebook=False)\n","    print(f'test_loss = {test_loss}; test_acc = {test_acc}')\n","    dump_train_state_to_json(train_state, args.train_state_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jse3RDm_8lj1","colab_type":"code","colab":{}},"source":["import os\n","\n","def expand_paths(args):\n","    args.model_save_file = os.path.join(args.save_dir, args.model_save_file)\n","    args.train_state_file = os.path.join(args.save_dir, args.train_state_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyuufT1J8pjB","colab_type":"code","colab":{}},"source":["expand_paths(args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CcalQG94rmw_","colab_type":"code","outputId":"695761e2-5966-4183-cda8-3a0185b7cbf2","executionInfo":{"status":"ok","timestamp":1586890297306,"user_tz":-120,"elapsed":610,"user":{"displayName":"Josip Jukic","photoUrl":"","userId":"16297184793715183143"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["f55f51bdaa474b058aae68339f8adf82","446969938e1749abbde76e305d93fb20","451078f30efc4e6194b965e71f1e98a8","63ed84050aea49f8b804139735593429","7853268244be48219f706bc3e909ec61","c0c700709e8744ea93feb67e6a3beb2a","0d4868598903453eb5f695c6b22f426f","7a74f0dc8ca942eab216a0ddc29f7827","6bb0cb0ba6344521a78e0bed92f8fadd","c8db8ce766c04709a797e7465ae9a8fa","32966e234a4548029e5d6313919282c1","d001aca3a2034288a8c02caa4330da9f","2d8a9d4d0a4847bf8716a3759fcb7ca2","9e7f33f0faee4139b0a1bac6d0b185ef","0cce80787ce149fdb48d8d0761aa6d60","de4112f79c4d48bea559326348e57c08","a1aff443e0d34252a3b03b1a20aaea58","32223dab9f664e63a857ff2f71e24b89","1e26d93872094dbcba4efb2ea3853efe","4006ec3536e04bedaeba01f281900043","739fc68a28204ef2b066e78c4816ff3d","c7b9fb6cd031422bb9afe90c5f9e5e54","f87053b2e4a3439b825698c25c6813d3","380f1338c3264e61b7fb45945d7e1bed"]}},"source":["from tqdm.notebook import tqdm\n","\n","epoch_bar = tqdm(desc='training routine', \n","                 total=args.num_epochs,\n","                 position=0)\n","\n","train_bar = tqdm(desc='Train set',\n","                total=len(train_iterator), \n","                position=1)\n","\n","val_bar = tqdm(desc='Valid set',\n","              total=len(valid_iterator), \n","              position=1)"],"execution_count":173,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f55f51bdaa474b058aae68339f8adf82","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='training routine', max=5, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6bb0cb0ba6344521a78e0bed92f8fadd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Train set', max=274, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1aff443e0d34252a3b03b1a20aaea58","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Valid set', max=118, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"QnQTIem2I4cg","colab_type":"code","outputId":"cd3634a4-0490-4e07-94e1-015fe94608dc","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1586890472331,"user_tz":-120,"elapsed":172283,"user":{"displayName":"Josip Jukic","photoUrl":"","userId":"16297184793715183143"}}},"source":["model = model.to(args.device)\n","run_experiment(args, model, iterator, optimizer, criterion, True)"],"execution_count":174,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 31s\n","    Train Loss: 0.682 | Train Acc: 56.81%\n","    Valid Loss: 0.709 |  Valid Acc: 50.83%\n","Epoch: 02 | Epoch Time: 0m 31s\n","    Train Loss: 0.626 | Train Acc: 65.32%\n","    Valid Loss: 0.553 |  Valid Acc: 73.38%\n","Epoch: 03 | Epoch Time: 0m 31s\n","    Train Loss: 0.643 | Train Acc: 63.58%\n","    Valid Loss: 0.604 |  Valid Acc: 68.34%\n","Epoch: 04 | Epoch Time: 0m 31s\n","    Train Loss: 0.624 | Train Acc: 65.02%\n","    Valid Loss: 0.542 |  Valid Acc: 73.39%\n","Epoch: 05 | Epoch Time: 0m 31s\n","    Train Loss: 0.588 | Train Acc: 68.30%\n","    Valid Loss: 0.483 |  Valid Acc: 77.41%\n","test_loss = 0.48432496830325616; test_acc = 0.7724584398976985\n"],"name":"stdout"}]}]}