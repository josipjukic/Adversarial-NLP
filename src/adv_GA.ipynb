{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adv_GA.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"11yPgTuV9cItcg3dPqCQst5qCrxQyqATg","authorship_tag":"ABX9TyNe8wLCUU0lIKi0zB8PYxCK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"E0uOjyvR1dGw","colab_type":"text"},"source":["## Solving dependencies"]},{"cell_type":"markdown","metadata":{"id":"QWnFw3kDV0R4","colab_type":"text"},"source":["### Git repository, embeddings, NLTK"]},{"cell_type":"code","metadata":{"id":"_qFnZfB41J7D","colab_type":"code","colab":{}},"source":["! git clone https://github.com/josipjukic/Adversarial-NLP.git\n","% cd /content/Adversarial-NLP/src\n","\n","% mkdir .vector_cache\n","% cp '/content/drive/My Drive/Master Thesis/glove/glove.6B.100d.txt.pt' .vector_cache/\n","% cp '/content/drive/My Drive/Master Thesis/glove/counter-fitted-vectors.txt' .vector_cache/\n","\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKEZU9wG1wuS","colab_type":"text"},"source":["## Dataset save/load"]},{"cell_type":"code","metadata":{"id":"fAG4WVtC1LUe","colab_type":"code","colab":{}},"source":["import torch\n","from torchtext import data\n","from torchtext import datasets\n","import spacy\n","import random\n","from preprocessing import imdb_preprocess\n","from data_utils import load_dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"joKNAe6fWWbh","colab_type":"code","colab":{}},"source":["SEED = 42\n","torch.manual_seed(SEED)\n","LOAD_PATH = '/content/drive/My Drive/Master Thesis/IMDB'\n","MAX_VOCAB_SIZE = 25_000\n","EMBEDDINGS_FILE = 'glove.6B.100d'\n","\n","splits, fields = load_dataset(LOAD_PATH,\n","                              include_lengths=True,\n","                              lower=False,\n","                              stop_words=None)\n","train_data, valid_data, test_data = splits\n","TEXT, LABEL, RAW, ID = fields\n","RAW.is_target = ID.is_target = False\n","LABEL.build_vocab(train_data)\n","TEXT.build_vocab(train_data, \n","                 max_size=MAX_VOCAB_SIZE, \n","                 vectors=EMBEDDINGS_FILE, \n","                 unk_init=torch.Tensor.normal_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WSSsflavpNZD","colab_type":"code","colab":{}},"source":["from argparse import Namespace\n","from data_utils import expand_paths\n","from models import PackedLSTM\n","\n","args = Namespace(\n","    # Data and Path hyper parameters\n","    counter_vectors_paths='.vector_cache/counter-fitted-vectors.txt',\n","    model_path='/content/drive/My Drive/Master Thesis/torch_models/imdb/imdb_model.torch',\n","    train_state_file='train_state.json',\n","    save_dir='/content/drive/My Drive/Master Thesis/torch_models/imdb/',\n","    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token],\n","    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token],\n","    # Model hyper parameters\n","    input_dim = len(TEXT.vocab),\n","    embedding_dim=100,\n","    hidden_dim=256,\n","    output_dim = 1,\n","    num_layers=2,\n","    bidirectional=True,\n","    # Training hyper parameter\n","    seed=SEED,\n","    learning_rate=0.001,\n","    dropout_p=0.5,\n","    batch_size=64,\n","    num_epochs=20,\n","    early_stopping_criteria=5,\n","    # Runtime option\n","    reload_from_files=True,\n","    expand_filepaths_to_save_dir=True,\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",")\n","\n","pretrained_embeddings = TEXT.vocab.vectors\n","pretrained_embeddings[args.UNK_IDX] = torch.zeros(args.embedding_dim)\n","pretrained_embeddings[args.PAD_IDX] = torch.zeros(args.embedding_dim)\n","\n","model = PackedLSTM(\n","    args.embedding_dim, \n","    args.hidden_dim, \n","    args.output_dim, \n","    args.num_layers,\n","    pretrained_embeddings,\n","    args.bidirectional,\n","    args.dropout_p, \n","    args.PAD_IDX,\n","    args.device\n",")\n","model.load_state_dict(torch.load(args.model_path, map_location=args.device))\n","model = model.to(args.device)\n","model.eval()\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size=1,\n","    sort_within_batch=True,\n","    sort_key = lambda x: len(x.text),\n","    device=args.device)\n","iterator = dict(train=train_iterator, valid=valid_iterator, test=test_iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yLKthJhJmjxG","colab_type":"code","colab":{}},"source":["from data_utils import spacy_revtok\n","import numpy as np\n","\n","num_classes = len(LABEL.vocab)\n","nlp = spacy.load('en', disable=['parser', 'tagger', 'ner', 'textcat'])\n","\n","\n","def binary_accuracy(model, batch):\n","    y_pred = model.predict(batch.text).to(args.device).squeeze()\n","    correct = (y_pred == batch.label).float()\n","    return (correct.sum() / len(correct)).item()\n","\n","\n","attack_power = 20\n","reg_acc = 0.\n","adv_acc = 0.\n","# for batch_index, batch in enumerate(iterator['test'], 1):\n","#     # print('Length: ', batch.text[0].shape[0])\n","#     print('Batch: ', batch_index)\n","#     x_in, lengths = batch.text\n","#     y_preds = model.predict(batch.text)\n","#     losses = word_target(model=model, batch=batch.text,\n","#                          y_preds=y_preds, num_classes=num_classes,\n","#                          device=args.device)\n","#     sorted_losses, indices = torch.sort(losses, dim=0, descending=True)\n","#     acc_t = binary_accuracy(model, batch)\n","#     reg_acc += (acc_t - reg_acc) / batch_index\n","\n","\n","#     for i in range(x_in.shape[1]):\n","#         inds = indices[0:attack_power,i]\n","#         x_in[inds,i] = 0\n","#         print(adversarial_text(batch.raw[i], nlp, inds, homoglyph))\n","#         print(batch.raw[i])\n","\n","#     acc_t = binary_accuracy(model, batch)\n","#     adv_acc += (acc_t - adv_acc) / batch_index\n","#     print(reg_acc, adv_acc)\n","#     print('-----------------------------')\n","#     break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ndNbATMNbotn","colab":{}},"source":["import numpy as np\n","import torch.nn.functional as F\n","\n","\n","def softmax(x):\n","    exp = np.exp(x)\n","    return exp / exp.sum()\n","\n","def prob_normalize(x):\n","    s = np.sum(x)\n","    if s == 0: return x\n","    return x / s\n","\n","\n","class Attack():\n","    def __init__(self, model, LS,\n","                 pop_size=20, max_iters=5,\n","                 top_n=10, packed=True, filter_spec=False,\n","                 greedy=False, targeted=True,\n","                 device='cuda' if torch.cuda.is_available() else 'cpu'):\n","        self.model = model\n","        self.LS = LS\n","        self.max_iters = max_iters\n","        self.pop_size = pop_size\n","        self.top_n = top_n  # similar words\n","        self.packed = packed\n","        self.filter_spec = filter_spec\n","        self.greedy = greedy\n","        self.targeted = targeted\n","        self.device = device\n","\n","    def prepare_batch(self, xs):\n","        x_in = torch.from_numpy(xs).permute(1,0).to(self.device)\n","        if self.packed:\n","            length = x_in.shape[0]\n","            N = x_in.shape[1]\n","            return x_in, torch.tensor(length, device=self.device).repeat(N)\n","        else:\n","            return x_in\n","\n","    def to_numpy(self, tensor):\n","        return tensor.cpu().numpy()\n","\n","    def do_replace(self, x_cur, pos, new_word):\n","        x_new = x_cur.copy()\n","        x_new[pos] = new_word\n","        return x_new\n","\n","    def select_replacement(self, pos, x_cur, x_orig, target, subs):\n","        new_xs = [self.do_replace(x_cur, pos, w)\n","                  if x_orig[pos] != w and w != 0 \\\n","                  else x_cur \\\n","                  for w in subs]\n","        \n","        batch = self.prepare_batch(np.array(new_xs))\n","        new_preds = self.model.predict_proba(batch)\n","        new_scores = new_preds[:, target]\n","\n","        if not self.targeted:\n","            new_scores = 1. - new_scores\n","\n","        # For greedy approach.\n","        # batch = self.prepare_batch(x_cur[np.newaxis, :])\n","        # orig_score = self.model.predict_proba(batch)[0, target]\n","        # new_x_scores = new_x_scores - orig_score\n","        # new_x_scores = self.to_numpy(new_x_scores)\n","\n","        if self.greedy:\n","            idx = torch.argmax(new_scores)\n","        else:\n","            torch_probs = F.softmax(new_scores, dim=0)\n","            probs = self.to_numpy(torch_probs)\n","            idx = np.random.choice(len(new_xs), size=1, p=probs)[0]\n","        \n","        return new_xs[idx]\n","\n","    def perturb(self, x_cur, x_orig, nghbrs, probs, target):\n","        x_len = probs.shape[0]\n","        idx = np.random.choice(x_len, size=1, p=probs)[0]\n","        subs = nghbrs[idx]\n","        \n","        if subs.size == 0:\n","            return x_cur\n","\n","        return self.select_replacement(idx, x_cur, x_orig, target, subs)\n","\n","    def generate_population(self, x_orig, nghbr_list,\n","                            probs, target, pop_size):\n","        \n","        return np.array(\n","            [self.perturb(\n","                x_orig, x_orig, nghbr_list,\n","                nghbr_dist, probs, target\n","             )\n","             for _ in range(pop_size)]\n","        )\n","\n","    def crossover(self, x1, x2):\n","        # add different crossover\n","        x_new = x1.copy()\n","        for i in range(len(x1)):\n","            if np.random.uniform() < 0.5:\n","                x_new[i] = x2[i]\n","        return x_new\n","\n","    def attack(self, x_orig, target, sentence=None, weights=None,\n","               n_candidates=10, n_substitutes=10):\n","        x_adv = x_orig.copy()\n","        \n","        nghbr_list = self.LS.get_candidates(words=x_orig,\n","                                            n_candidates=n_candidates,\n","                                            n_substitutes=n_substitutes,\n","                                            sentence=sentence)\n","        nghbr_len = [len(list_i) for list_i in nghbr_list]\n","        if weights is None:\n","            sub_probs = nghbr_len / np.sum(nghbr_len)\n","        else:\n","            sub_probs = prob_normalize(nghbr_len * weights)\n","\n","        if self.filter_spec:\n","            for i, word in enumerate(x_orig):\n","                if word in self.LS.spec_words:\n","                    sub_probs[i] = 0.\n","            sub_probs = prob_normalize(sub_probs)\n","\n","        pop = self.generate_population(\n","            x_orig, nghbr_list, sub_probs, target, self.pop_size)\n","        \n","        for i in range(self.max_iters):\n","            batch = self.prepare_batch(pop)\n","            pop_preds = self.to_numpy(self.model.predict_proba(batch))\n","            pop_scores = pop_preds[:, target]\n","            if not self.targeted:\n","                pop_scores = 1. - pop_scores\n","            \n","            top_attack = np.argmax(pop_scores)\n","            select_probs = softmax(pop_scores)\n","\n","            print('\\t\\t', i, ' -- ', np.max(pop_scores))\n","\n","            if self.targeted:\n","                if np.argmax(pop_preds[top_attack, :]) == target:\n","                    print('Success!')\n","                    return pop[top_attack]\n","            else:\n","                if np.argmax(pop_preds[top_attack, :]) != target:\n","                    print('Success!')\n","                    return pop[top_attack]\n","            \n","            elite = [pop[top_attack]]\n","            parent1_idx = np.random.choice(\n","                self.pop_size, size=self.pop_size-1, p=select_probs)\n","            parent2_idx = np.random.choice(\n","                self.pop_size, size=self.pop_size-1, p=select_probs)\n","\n","            children = [self.crossover(pop[parent1_idx[i]],\n","                                       pop[parent2_idx[i]])\n","                       for i in range(self.pop_size-1)]\n","            children = [self.perturb(\n","                        x, x_orig, nghbr_list, sub_probs, target)\n","                        for x in children]\n","            pop = np.concatenate([elite, children])\n","\n","        return pop[0] if top_attack is None else pop[top_attack]\n","\n","\n","gen_at = Attack(model, ls)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NBeUSsoOCj8_","colab_type":"code","colab":{}},"source":["num = TEXT.numericalize(([['this', 'movie', 'is', 'very', 'annoying']], [5]), device=args.device)\n","x_in, _ = num\n","x = x_in.cpu().numpy().flatten()\n","print(model.predict(num))\n","model.eval()\n","gen_at.filter_spec = True\n","gen_at.greedy = True\n","with torch.no_grad():\n","    r = gen_at.attack(x, 0)\n","    print(replacing_adversarial_text('this movie is very annoying', nlp, r, TEXT.vocab))"],"execution_count":0,"outputs":[]}]}