{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"datasets.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"14d0xYBuS0l_4j5x8XTdfehKP5jW2VKdH","authorship_tag":"ABX9TyN/K88w3RPWRjC+6ZbRreey"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"E0uOjyvR1dGw","colab_type":"text"},"source":["## Solving dependecies"]},{"cell_type":"markdown","metadata":{"id":"QWnFw3kDV0R4","colab_type":"text"},"source":["### Git repo"]},{"cell_type":"code","metadata":{"id":"_qFnZfB41J7D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"21d41b91-97d9-4de7-8934-f2ed9216f3b8","executionInfo":{"status":"ok","timestamp":1587659557044,"user_tz":-120,"elapsed":5255,"user":{"displayName":"Josip Jukic","photoUrl":"","userId":"16297184793715183143"}}},"source":["! git clone https://github.com/josipjukic/Adversarial-NLP.git\n","% cd /content/Adversarial-NLP/src"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'Adversarial-NLP'...\n","remote: Enumerating objects: 224, done.\u001b[K\n","remote: Counting objects: 100% (224/224), done.\u001b[K\n","remote: Compressing objects: 100% (151/151), done.\u001b[K\n","remote: Total 224 (delta 132), reused 133 (delta 62), pack-reused 0\u001b[K\n","Receiving objects: 100% (224/224), 75.47 KiB | 415.00 KiB/s, done.\n","Resolving deltas: 100% (132/132), done.\n","/content/Adversarial-NLP/src\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NWNmPxPDWCJ2","colab_type":"text"},"source":["### Embeddings"]},{"cell_type":"code","metadata":{"id":"YxLhCQAtWA3n","colab_type":"code","colab":{}},"source":["% mkdir .vector_cache\n","% cp '/content/drive/My Drive/Master Thesis/glove/glove.6B.100d.txt.pt' .vector_cache/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iuWKabZYWF_q","colab_type":"text"},"source":["### NLTK data"]},{"cell_type":"code","metadata":{"id":"txnHPPV8wopS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"8e47c79d-bc8c-402a-d5a5-5b1f7a535649","executionInfo":{"status":"ok","timestamp":1587659568848,"user_tz":-120,"elapsed":14498,"user":{"displayName":"Josip Jukic","photoUrl":"","userId":"16297184793715183143"}}},"source":["import nltk\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"OKEZU9wG1wuS","colab_type":"text"},"source":["## Dataset save/load"]},{"cell_type":"code","metadata":{"id":"fAG4WVtC1LUe","colab_type":"code","colab":{}},"source":["import torch\n","from torchtext import data\n","from torchtext import datasets\n","import spacy\n","import random\n","from nltk.corpus import stopwords"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gAZuwoFOUVR5","colab_type":"text"},"source":["### Save dataset"]},{"cell_type":"code","metadata":{"id":"VA5ROBbW173-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"2f8ef59f-9716-4614-ae3a-43a37af4dc1a","executionInfo":{"status":"ok","timestamp":1587660666395,"user_tz":-120,"elapsed":77618,"user":{"displayName":"Josip Jukic","photoUrl":"","userId":"16297184793715183143"}}},"source":["from preprocessing import imdb_preprocess\n","from data_utils import save_dataset\n","\n","SEED = 42\n","torch.manual_seed(SEED)\n","SAVE_PATH = '/content/drive/My Drive/Master Thesis/IMDB'\n","\n","TEXT = data.RawField(preprocessing=imdb_preprocess)\n","LABEL = data.LabelField(dtype=torch.float)\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n","train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n","\n","dataset = dict(train=train_data, test=test_data, valid=valid_data)\n","save_dataset(dataset, SAVE_PATH)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Saved data at /content/drive/My Drive/Master Thesis/IMDB_plain/train.json.\n","Saved data at /content/drive/My Drive/Master Thesis/IMDB_plain/test.json.\n","Saved data at /content/drive/My Drive/Master Thesis/IMDB_plain/valid.json.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SbE1rrjybAch","colab_type":"text"},"source":["### Load dataset"]},{"cell_type":"code","metadata":{"id":"joKNAe6fWWbh","colab_type":"code","colab":{}},"source":["from data_utils import load_dataset\n","\n","SEED = 42\n","torch.manual_seed(SEED)\n","LOAD_PATH = '/content/drive/My Drive/Master Thesis/IMDB'\n","MAX_VOCAB_SIZE = 25_000\n","EMBEDDINGS_FILE = 'glove.6B.100d'\n","\n","splits, fields = load_dataset(LOAD_PATH)\n","train_data, valid_data, test_data = splits\n","TEXT, LABEL, RAW, ID = fields\n","RAW.is_target = ID.is_target = False\n","LABEL.build_vocab(train_data)\n","TEXT.build_vocab(train_data, \n","                 max_size = MAX_VOCAB_SIZE, \n","                 vectors = EMBEDDINGS_FILE, \n","                 unk_init = torch.Tensor.normal_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMDRwRWl1UIl","colab_type":"code","colab":{}},"source":["from argparse import Namespace\n","from data_utils import expand_paths\n","from models import PackedLSTM\n","\n","args = Namespace(\n","    # Data and Path hyper parameters\n","    model_save_file='imdb_model.torch',\n","    train_state_file='train_state.json',\n","    save_dir='/content/drive/My Drive/Master Thesis/torch_models/imdb/',\n","    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token],\n","    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token],\n","    # Model hyper parameters\n","    input_dim = len(TEXT.vocab),\n","    embedding_dim=100,\n","    hidden_dim=256,\n","    output_dim = 1,\n","    num_layers=2,\n","    bidirectional=True,\n","    # Training hyper parameter\n","    seed=SEED,\n","    learning_rate=0.001,\n","    dropout_p=0.5,\n","    batch_size=64,\n","    num_epochs=20,\n","    early_stopping_criteria=5,\n","    # Runtime option\n","    reload_from_files=True,\n","    expand_filepaths_to_save_dir=True,\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",")\n","\n","expand_paths(args)\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size=args.batch_size,\n","    sort_within_batch=True,\n","    sort_key = lambda x: len(x.text),\n","    device=args.device)\n","iterator = dict(train=train_iterator, valid=valid_iterator, test=test_iterator)\n","\n","pretrained_embeddings = TEXT.vocab.vectors\n","pretrained_embeddings[args.UNK_IDX] = torch.zeros(args.embedding_dim)\n","pretrained_embeddings[args.PAD_IDX] = torch.zeros(args.embedding_dim)\n","\n","model = PackedLSTM(\n","    args.embedding_dim, \n","    args.hidden_dim, \n","    args.output_dim, \n","    args.num_layers,\n","    pretrained_embeddings,\n","    args.bidirectional,\n","    args.dropout_p, \n","    args.PAD_IDX,\n","    args.device\n",")\n","\n","model = model.to(args.device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHW06qyRIC3H","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CcalQG94rmw_","colab_type":"code","colab":{}},"source":["from tqdm.notebook import tqdm\n","\n","epoch_bar = tqdm(desc='Training routine', \n","                 total=args.num_epochs,\n","                 position=0)\n","\n","train_bar = tqdm(desc='Train set',\n","                 total=len(train_iterator), \n","                 position=1)\n","\n","val_bar = tqdm(desc='Valid set',\n","               total=len(valid_iterator), \n","               position=1)\n","\n","tqdms = dict(main=epoch_bar, train=train_bar, valid=val_bar)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QnQTIem2I4cg","colab_type":"code","colab":{}},"source":["from training import run_experiment\n","\n","run_experiment(args, model, iterator, optimizer, criterion, tqdms)"],"execution_count":0,"outputs":[]}]}